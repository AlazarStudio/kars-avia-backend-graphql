/**
 * migrateUploads.js
 *
 * Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð°Ñ Ð¼Ð¸Ð³Ñ€Ð°Ñ†Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¸Ð· /uploads
 * Ð² ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾Ð´ÐºÐ°Ñ‚Ð°Ð»Ð¾Ð³Ð¸ + Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ ÑÑÑ‹Ð»Ð¾Ðº Ð² Ð‘Ð” + Ð¾Ñ‚Ñ‡Ñ‘Ñ‚
 * 
 * ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Ð½Ð¾Ð²Ð¾Ð¹ Ð·Ð°Ñ‰Ð¸Ñ‰ÐµÐ½Ð½Ð¾Ð¹ ÑÑ…ÐµÐ¼Ð¾Ð¹ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° Ðº Ñ„Ð°Ð¹Ð»Ð°Ð¼:
 * - Ð¤Ð°Ð¹Ð»Ñ‹ Ð¿ÐµÑ€ÐµÐ¼ÐµÑ‰Ð°ÑŽÑ‚ÑÑ Ð² ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ ÐºÐ°Ñ‚Ð°Ð»Ð¾Ð³Ð¸ uploads/bucket/entityId/YYYY/MM/DD/
 * - ÐŸÑƒÑ‚Ð¸ Ð² Ð‘Ð” Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÑŽÑ‚ÑÑ Ð½Ð° Ð½Ð¾Ð²Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ (Ð±ÐµÐ· Ð¿Ñ€ÐµÑ„Ð¸ÐºÑÐ° /files/, field resolvers Ð´Ð¾Ð±Ð°Ð²ÑÑ‚ ÐµÐ³Ð¾ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸)
 * - ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ÑÑ Ð¼Ð¸Ð³Ñ€Ð°Ñ†Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¸Ð· uploads, reports, reserve_files
 */

import fs from "fs"
import path from "path"
import cliProgress from "cli-progress"
import { prisma } from "../../prisma.js"
import { logger } from "../infra/logger.js"

/* =========================
   âš™ CONFIG
========================= */

const UPLOADS_ROOT = path.join(process.cwd(), "uploads")
const REPORTS_ROOT = path.join(process.cwd(), "reports")
const RESERVE_FILES_ROOT = path.join(process.cwd(), "reserve_files")
const REPORT_ROOT = path.join(process.cwd(), "reports/upload-migration")

const DRY_RUN = false // true â†’ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð»Ð¾Ð³, false â†’ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ Ð¿ÐµÑ€ÐµÐ½Ð¾ÑÐ¸Ñ‚

/* =========================
   ðŸ§  HELPERS
========================= */

const ensureDir = (dir) => {
  if (!fs.existsSync(dir)) {
    fs.mkdirSync(dir, { recursive: true })
  }
}

const isTopLevelFile = (file) => {
  try {
    return fs.statSync(path.join(UPLOADS_ROOT, file)).isFile()
  } catch {
    return false
  }
}

const getFileDateParts = (filePath) => {
  const stat = fs.statSync(filePath)
  const date = stat.birthtime ?? stat.mtime

  return {
    y: String(date.getFullYear()),
    m: String(date.getMonth() + 1).padStart(2, "0"),
    d: String(date.getDate()).padStart(2, "0")
  }
}

const buildTargetDir = ({ bucket, entityId, fileAbsPath, sourceRoot }) => {
  const { y, m, d } = getFileDateParts(fileAbsPath)

  // Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½ÑƒÑŽ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ°
  // Ð’ÑÐµ Ñ„Ð°Ð¹Ð»Ñ‹ Ð¼Ð¸Ð³Ñ€Ð¸Ñ€ÑƒÑŽÑ‚ÑÑ Ð² ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ uploads/bucket/entityId/YYYY/MM/DD/
  // Ð½ÐµÐ·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ Ð¾Ñ‚ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¾Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ (reports, reserve_files Ñ‚Ð¾Ð¶Ðµ Ð¸Ð´ÑƒÑ‚ Ð² uploads)
  const rootDir = UPLOADS_ROOT
  
  // Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð°: uploads/bucket/entityId/YYYY/MM/DD/ Ð¸Ð»Ð¸ uploads/bucket/YYYY/MM/DD/
  const parts = [rootDir, bucket]
  if (entityId) parts.push(entityId)
  parts.push(y, m, d)

  return path.join(...parts)
}

const normalizeUploadPath = (value) => {
  if (!value) return value
  const normalized = value.replace(/\\/g, "/")
  
  // Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¿Ñ€ÐµÑ„Ð¸ÐºÑ /files/ ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ (Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚Ð¸)
  let cleaned = normalized.replace(/^\/files\//, "")
  
  // Ð˜Ñ‰ÐµÐ¼ Ð¿ÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ Ð² Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… ÐºÐ¾Ñ€Ð½ÐµÐ²Ñ‹Ñ… Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑÑ…
  let idx = cleaned.indexOf("/uploads/")
  if (idx === -1) idx = cleaned.indexOf("uploads/")
  if (idx === -1) {
    idx = cleaned.indexOf("/reports/")
    if (idx === -1) idx = cleaned.indexOf("reports/")
  }
  if (idx === -1) {
    idx = cleaned.indexOf("/reserve_files/")
    if (idx === -1) idx = cleaned.indexOf("reserve_files/")
  }
  
  if (idx === -1) return cleaned
  
  let sub = cleaned.slice(idx)
  if (!sub.startsWith("/")) sub = `/${sub}`
  return sub
}

const buildOldVariants = (oldPath) => {
  const normalized = normalizeUploadPath(oldPath) || oldPath
  const noLeading = normalized?.replace(/^\/+/, "")
  return Array.from(new Set([oldPath, normalized, noLeading])).filter(Boolean)
}

const replaceInArray = (arr, oldVariants, newPath) =>
  arr?.map((p) => {
    if (!p) return p
    
    // ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ð¹ Ð¿ÑƒÑ‚ÑŒ
    const normalizedP = normalizeUploadPath(p)
    
    for (const oldPath of oldVariants) {
      const normalizedOld = normalizeUploadPath(oldPath)
      
      // Ð¢Ð¾Ñ‡Ð½Ð¾Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ
      if (p === oldPath || normalizedP === normalizedOld) {
        return newPath
      }
      
      // Ð§Ð°ÑÑ‚Ð¸Ñ‡Ð½Ð¾Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ (Ð¿ÑƒÑ‚ÑŒ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ ÑÑ‚Ð°Ñ€Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ)
      if (p.includes(oldPath) || normalizedP.includes(normalizedOld)) {
        return p.replace(oldPath, newPath).replace(`/files${normalizedOld}`, newPath)
      }
    }
    return p
  })

/* =========================
   ðŸ” FILE CLASSIFICATION
========================= */

const resolveFileOwner = async (oldRelPath) => {
  // ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼ Ð¿ÑƒÑ‚ÑŒ Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ° (ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ /files/ ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ)
  const normalizedPath = normalizeUploadPath(oldRelPath)
  
  // Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ñ‹ Ð¿ÑƒÑ‚Ð¸ Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ° (Ñ /files/ Ð¸ Ð±ÐµÐ·)
  const searchVariants = [
    oldRelPath,
    normalizedPath,
    `/files${normalizedPath}`,
    normalizedPath.replace(/^\//, "")
  ]

  // Ð˜Ñ‰ÐµÐ¼ Ð² requests
  for (const variant of searchVariants) {
    const request = await prisma.request.findFirst({
      where: { files: { has: variant } },
      select: { id: true }
    })
    if (request) return { bucket: "requests", entityId: request.id }
  }

  // Ð˜Ñ‰ÐµÐ¼ Ð² reserves
  for (const variant of searchVariants) {
    const reserve = await prisma.reserve.findFirst({
      where: { files: { has: variant } },
      select: { id: true }
    })
    if (reserve) return { bucket: "reserves", entityId: reserve.id }
    
    // Ð¢Ð°ÐºÐ¶Ðµ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ passengerList
    const reserveWithList = await prisma.reserve.findFirst({
      where: { passengerList: { has: variant } },
      select: { id: true }
    })
    if (reserveWithList) return { bucket: "reserves", entityId: reserveWithList.id }
  }

  // Ð˜Ñ‰ÐµÐ¼ Ð² users
  for (const variant of searchVariants) {
    const user = await prisma.user.findFirst({
      where: { images: { has: variant } },
      select: { id: true }
    })
    if (user) return { bucket: "users", entityId: user.id }
  }

  // Ð˜Ñ‰ÐµÐ¼ Ð² airlinePersonal
  for (const variant of searchVariants) {
    const personal = await prisma.airlinePersonal.findFirst({
      where: { images: { has: variant } },
      select: { id: true }
    })
    if (personal) return { bucket: "airline-personal", entityId: personal.id }
  }

  // Ð˜Ñ‰ÐµÐ¼ Ð² contracts
  for (const variant of searchVariants) {
    const airlineContract = await prisma.airlineContract.findFirst({
      where: { files: { has: variant } },
      select: { id: true }
    })
    if (airlineContract) return { bucket: "contracts", entityId: airlineContract.id }
    
    const hotelContract = await prisma.hotelContract.findFirst({
      where: { files: { has: variant } },
      select: { id: true }
    })
    if (hotelContract) return { bucket: "contracts", entityId: hotelContract.id }
    
    const orgContract = await prisma.organizationContract.findFirst({
      where: { files: { has: variant } },
      select: { id: true }
    })
    if (orgContract) return { bucket: "contracts", entityId: orgContract.id }
  }

  return { bucket: "misc", entityId: null }
}

/* =========================
   ðŸ—º MIGRATION MAP
========================= */

const migrationMap = []

/* =========================
   ðŸ”„ DB UPDATE CONFIG
========================= */

const UPDATE_TARGETS = [
  { model: "request", fields: ["files"] },
  { model: "reserve", fields: ["files", "passengerList"] },
  { model: "user", fields: ["images"] },
  { model: "airlinePersonal", fields: ["images"] },
  { model: "airline", fields: ["images"] },
  { model: "hotel", fields: ["images", "gallery"] },
  { model: "room", fields: ["images"] },
  { model: "roomKind", fields: ["images"] },
  { model: "additionalServices", fields: ["images"] },
  { model: "airlineContract", fields: ["files"] },
  { model: "additionalAgreement", fields: ["files"] },
  { model: "hotelContract", fields: ["files"] },
  { model: "organizationContract", fields: ["files"] },
  { model: "documentation", fields: ["files", "images"] },
  { model: "patchNote", fields: ["files", "images"] },
  { model: "transfer", fields: ["files"] }
]

const updateDatabaseLinks = async () => {
  let updated = 0

  for (const item of migrationMap) {
    if (item.status !== "moved") continue

    for (const target of UPDATE_TARGETS) {
      const model = prisma[target.model]
      if (!model) continue

      for (const field of target.fields) {
        const oldVariants = buildOldVariants(item.old)
        const records = await model.findMany({
          where: { [field]: { hasSome: oldVariants } },
          select: { id: true, [field]: true }
        })

        for (const rec of records) {
          const updatedField = replaceInArray(rec[field], oldVariants, item.new)
          if (
            !updatedField ||
            JSON.stringify(updatedField) === JSON.stringify(rec[field])
          )
            continue

          await model.update({
            where: { id: rec.id },
            data: {
              [field]: updatedField
            }
          })
          updated++
        }
      }
    }
  }

  logger.info(`[DB] Updated links: ${updated}`)
}

/* =========================
   ðŸšš MIGRATION
========================= */

/**
 * ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð¸ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ Ð¿Ð¾ Ð¿Ð¾Ð»Ð½Ð¾Ð¼Ñƒ Ð¿ÑƒÑ‚Ð¸ Ñ„Ð°Ð¹Ð»Ð°
 */
const getSourceInfo = (filePath) => {
  if (filePath.startsWith(UPLOADS_ROOT)) {
    return {
      root: UPLOADS_ROOT,
      rootName: "uploads",
      relative: path.relative(UPLOADS_ROOT, filePath).replace(/\\/g, "/")
    }
  }
  if (filePath.startsWith(REPORTS_ROOT)) {
    return {
      root: REPORTS_ROOT,
      rootName: "reports",
      relative: path.relative(REPORTS_ROOT, filePath).replace(/\\/g, "/")
    }
  }
  if (filePath.startsWith(RESERVE_FILES_ROOT)) {
    return {
      root: RESERVE_FILES_ROOT,
      rootName: "reserve_files",
      relative: path.relative(RESERVE_FILES_ROOT, filePath).replace(/\\/g, "/")
    }
  }
  // ÐŸÐ¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ uploads
  return {
    root: UPLOADS_ROOT,
    rootName: "uploads",
    relative: path.relative(UPLOADS_ROOT, filePath).replace(/\\/g, "/")
  }
}

const migrate = async () => {
  ensureDir(REPORT_ROOT)

  // Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ñ„Ð°Ð¹Ð»Ñ‹ Ð¸Ð· Ð²ÑÐµÑ… ÐºÐ¾Ñ€Ð½ÐµÐ²Ñ‹Ñ… Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹
  const filesToMigrate = []

  // Ð¤Ð°Ð¹Ð»Ñ‹ Ð¸Ð· uploads (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð²ÐµÑ€Ñ…Ð½ÐµÐ³Ð¾ ÑƒÑ€Ð¾Ð²Ð½Ñ, Ð½Ðµ Ð² Ð¿Ð¾Ð´ÐºÐ°Ñ‚Ð°Ð»Ð¾Ð³Ð°Ñ…)
  if (fs.existsSync(UPLOADS_ROOT)) {
    const uploadsFiles = fs
      .readdirSync(UPLOADS_ROOT)
      .filter((f) => f !== "migrated" && f !== "requests" && f !== "reserves" && f !== "users" && f !== "misc" && f !== "images" && f !== "airline-personal" && f !== "contracts")
      .filter((f) => isTopLevelFile(f))
      .map((f) => ({
        file: f,
        absPath: path.join(UPLOADS_ROOT, f),
        sourceRoot: UPLOADS_ROOT
      }))
    filesToMigrate.push(...uploadsFiles)
  }

  logger.info(`[MIGRATE] Found ${filesToMigrate.length} files to migrate`)

  if (filesToMigrate.length === 0) {
    logger.info("[MIGRATE] No files to migrate")
    await prisma.$disconnect()
    return
  }

  const bar = new cliProgress.SingleBar(
    {
      format: "MIGRATING |{bar}| {percentage}% | {value}/{total}",
      hideCursor: true
    },
    cliProgress.Presets.shades_classic
  )

  bar.start(filesToMigrate.length, 0)

  for (const fileInfo of filesToMigrate) {
    try {
      const { file, absPath, sourceRoot } = fileInfo
      const sourceInfo = getSourceInfo(absPath)
      
      // Ð¡Ñ‚Ð°Ñ€Ñ‹Ð¹ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ (Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ° Ð² Ð‘Ð”)
      const oldRel = `/${sourceInfo.rootName}/${sourceInfo.relative}`
      
      // ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð²Ð»Ð°Ð´ÐµÐ»ÑŒÑ†Ð° Ñ„Ð°Ð¹Ð»Ð°
      const { bucket, entityId } = await resolveFileOwner(oldRel)
      
      // ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ†ÐµÐ»ÐµÐ²ÑƒÑŽ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ
      const targetDir = buildTargetDir({
        bucket,
        entityId,
        fileAbsPath: absPath,
        sourceRoot: sourceRoot || UPLOADS_ROOT
      })

      ensureDir(targetDir)

      // ÐÐ¾Ð²Ð¾Ðµ Ð¸Ð¼Ñ Ñ„Ð°Ð¹Ð»Ð° Ñ timestamp
      const timestamp = Date.now()
      const fileExt = path.extname(file)
      const fileName = path.basename(file, fileExt)
      const safeFileName = fileName.replace(/[^a-z0-9\-_.]/gi, "").slice(0, 80)
      const newName = `${timestamp}-${safeFileName}${fileExt}`
      const newAbs = path.join(targetDir, newName)
      
      // ÐÐ¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ (Ð±ÐµÐ· Ð¿Ñ€ÐµÑ„Ð¸ÐºÑÐ° /files/, field resolvers Ð´Ð¾Ð±Ð°Ð²ÑÑ‚ ÐµÐ³Ð¾ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸)
      // Ð’ÑÐµ Ñ„Ð°Ð¹Ð»Ñ‹ Ð¼Ð¸Ð³Ñ€Ð¸Ñ€ÑƒÑŽÑ‚ÑÑ Ð² ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ uploads/bucket/...
      const newRel = "/uploads/" + path.relative(UPLOADS_ROOT, newAbs).replace(/\\/g, "/")

      logger.info(`[MOVE] ${oldRel} â†’ ${newRel}`)

      if (!DRY_RUN) {
        // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ñ†ÐµÐ»ÐµÐ²Ð¾Ð¹ Ñ„Ð°Ð¹Ð» Ð½Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚
        if (fs.existsSync(newAbs)) {
          logger.warn(`[SKIP] Target file already exists: ${newAbs}`)
          migrationMap.push({
            old: oldRel,
            new: newRel,
            bucket,
            entityId,
            status: "skipped",
            reason: "target_exists"
          })
          continue
        }
        
        fs.renameSync(absPath, newAbs)
      }

      migrationMap.push({
        old: oldRel,
        new: newRel,
        bucket,
        entityId,
        sourceRoot: sourceInfo.rootName,
        status: DRY_RUN ? "dry-run" : "moved"
      })
    } catch (e) {
      logger.error(`[MIGRATE ERROR] ${fileInfo.file}`, e)
      migrationMap.push({
        old: fileInfo.file,
        status: "error",
        error: e.message,
        stack: e.stack
      })
    } finally {
      bar.increment()
    }
  }

  bar.stop()

  /* =========================
     ðŸ§¾ SAVE REPORT
  ========================= */

  const reportPath = path.join(
    REPORT_ROOT,
    `migration-${new Date().toISOString().slice(0, 10)}-${Date.now()}.json`
  )

  ensureDir(REPORT_ROOT)
  fs.writeFileSync(reportPath, JSON.stringify(migrationMap, null, 2))
  logger.info(`[REPORT] Saved: ${reportPath}`)

  // Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
  const stats = {
    total: migrationMap.length,
    moved: migrationMap.filter((m) => m.status === "moved").length,
    dryRun: migrationMap.filter((m) => m.status === "dry-run").length,
    errors: migrationMap.filter((m) => m.status === "error").length,
    skipped: migrationMap.filter((m) => m.status === "skipped").length
  }
  
  logger.info(`[STATS] Total: ${stats.total}, Moved: ${stats.moved}, Errors: ${stats.errors}, Skipped: ${stats.skipped}`)

  /* =========================
     ðŸ”„ UPDATE DB
  ========================= */

  if (!DRY_RUN && stats.moved > 0) {
    logger.info("[DB] Starting database links update...")
    await updateDatabaseLinks()
    logger.info("[DB] Database links update completed")
  } else if (DRY_RUN) {
    logger.info("[DB] DRY RUN mode - skipping database update")
  } else {
    logger.info("[DB] No files moved - skipping database update")
  }

  await prisma.$disconnect()
}

/* =========================
   â–¶ RUN
========================= */

migrate()
  .then(() => {
    logger.info("[MIGRATE] Completed successfully")
    process.exit(0)
  })
  .catch((e) => {
    logger.error("[MIGRATE] Failed", e)
    process.exit(1)
  })
